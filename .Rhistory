n = 15L,
margin = .2,
labelsize = 3)
Fox_keyness_2 <- textstat_keyness(key_dfm_2, target = "FOXNEWSW")
key_dfm_2 <- dfm(toks_2, groups = "channel")
key_dfm_2 <- dfm(toks_2, groups = "channel")
CNN_keyness_2 <- textstat_keyness(key_dfm_2, target = "CNNW")
CNN_key_2 <- textplot_keyness(CNN_keyness_2,
n = 15L,
margin = .2,
labelsize = 3)
Fox_keyness_2 <- textstat_keyness(key_dfm_2, target = "FOXNEWSW")
Fox_key_2 <- textplot_keyness(Fox_keyness_2,
n = 15L,
margin = .2,
labelsize = 3)
MSNBC_keyness_2 <- textstat_keyness(key_dfm_2, target = "MSNBCW")
MSNBC_key_2 <- textplot_keyness(MSNBC_keyness_2,
n = 15L,
margin = .2,
labelsize = 3)
ggarrange(Fox_key_2, MSNBC_key_2)
ggarrange(CNN_key_2, Fox_key_2, MSNBC_key_2)
MSNBC_key_2 <- textplot_keyness(MSNBC_keyness_2,
n = 15L,
margin = .5,
labelsize = 3)
MSNBC_key_2
ggarrange(CNN_key_2, Fox_key_2, MSNBC_key_2)
ggarrange(CNN_key_2, Fox_key_2, MSNBC_key_2,
nrow = 3)
CNN_key_2 <- textplot_keyness(CNN_keyness_2,
n = 15L,
margin = .7,
labelsize = 3)
MSNBC_keyness_2 <- textstat_keyness(key_dfm_2, target = "MSNBCW")
MSNBC_key_2 <- textplot_keyness(MSNBC_keyness_2,
n = 15L,
margin = .7,
labelsize = 3)
ggarrange(CNN_key_2, Fox_key_2, MSNBC_key_2,
nrow = 3)
CNN_key_2
Fox_key_2 <- textplot_keyness(Fox_keyness_2,
n = 15L,
margin = .2,
labelsize = 3)
Fox_key_2
Fox_key_2 <- textplot_keyness(Fox_keyness_2,
n = 15L,
margin = .2,
labelsize = 3)
MSNBC_keyness_2 <- textstat_keyness(key_dfm_2, target = "MSNBCW")
MSNBC_keyness_2 <- textstat_keyness(key_dfm_2, target = "MSNBCW")
MSNBC_key_2 <- textplot_keyness(MSNBC_keyness_2,
n = 15L,
margin = .2,
labelsize = 3)
MSNBC_key_2 <- textplot_keyness(MSNBC_keyness_2,
n = 15L,
margin = .2,
labelsize = 3)
ggarrange(CNN_key_2, Fox_key_2, MSNBC_key_2,
nrow = 3)
key_dfm_3 <- dfm(toks_3, groups = "channel")
# CNN keyness
CNN_keyness_3 <- textstat_keyness(key_dfm_3, target = "CNNW")
CNN_key_3 <- textplot_keyness(CNN_keyness_3,
n = 15L,
margin = .2,
labelsize = 3)
# Fox keyness
Fox_keyness_3 <- textstat_keyness(key_dfm_3, target = "FOXNEWSW")
Fox_key_3 <- textplot_keyness(Fox_keyness_3,
n = 15L,
margin = .2,
labelsize = 3)
# MSNBC keyness
MSNBC_keyness_3 <- textstat_keyness(key_dfm_3, target = "MSNBCW")
MSNBC_key_3 <- textplot_keyness(MSNBC_keyness_3,
n = 15L,
margin = .2,
labelsize = 3)
CNN_key_3
Fox_key_3
MSNBC_key_3
knitr::opts_chunk$set(echo = TRUE)
# Loading necessary packages
library(gt)
library(quanteda)
library(broom)
library(skimr)
library(lubridate)
library(janitor)
library(dotwhisker)
library(tidytext)
library(haven)
library(ggthemes)
library(webshot)
library(stargazer)
library(tidyverse)
library(patchwork)
library(ggrepel)
library(ggpubr)
tidy_chyrons <- read_csv("tidy_chyron_data.csv")
# Turning data into a corpus for quanteda
text_corpus <- corpus(tidy_chyrons, text_field = "text")
summary(tidy_chyrons)
skim(tidy_chyrons)
knitr::opts_chunk$set(echo = TRUE)
# Loading necessary packages
library(gt)
library(quanteda)
library(broom)
library(skimr)
library(lubridate)
library(janitor)
library(dotwhisker)
library(tidytext)
library(haven)
library(ggthemes)
library(webshot)
library(stargazer)
library(tidyverse)
library(patchwork)
library(ggrepel)
library(ggpubr)
tidy_chyrons <- read_csv("tidy_chyron_data.csv")
# Turning data into a corpus for quanteda
text_corpus <- corpus(tidy_chyrons, text_field = "text")
View(tidy_chyrons)
# This time I am just going to use the data from after the 2020 election so it
# is consistent with the dictionaries. So we have from November 3, 2020 to
# today, November 17, 2021. It actually might make more sense to just look at
# the year so I am going to November 3, 2021.
library(tidyverse)
set.seed(1121)
random_numbers <- sample(1:52, 10, replace = FALSE)
devtools::install_github("hrbrmstr/newsflash")
set.seed(11)
random_numbers <- sample(1:52, 10, replace = FALSE)
random_numbers <- sample(c(1:16, 43:52), 10, replace = FALSE)
file_names <- c("data/bias_data/third_eye-08_31_21.tsv",
"data/bias_data/third_eye-01_19_21.tsv",
"data/bias_data/third_eye-09_28_21.tsv",
"data/bias_data/third_eye-11_24_20.tsv",
"data/bias_data/third_eye-12_22_20.tsv",
"data/bias_data/third_eye-02_02_21.tsv",
"data/bias_data/third_eye-12_29_20.tsv",
"data/bias_data/third_eye-11_17_20.tsv",
"data/bias_data/third_eye-10_12_21.tsv",
"data/bias_data/third_eye-02_16_21.tsv")
file <- read_csv("data/bias_data/third_eye-08_31_21.tsv")
file_names <- c("data/bias_data/third-eye-08_31_21.tsv",
"data/bias_data/third-eye-01_19_21.tsv",
"data/bias_data/third-eye-09_28_21.tsv",
"data/bias_data/third-eye-11_24_20.tsv",
"data/bias_data/third-eye-12_22_20.tsv",
"data/bias_data/third-eye-02_02_21.tsv",
"data/bias_data/third-eye-12_29_20.tsv",
"data/bias_data/third-eye-11_17_20.tsv",
"data/bias_data/third-eye-10_12_21.tsv",
"data/bias_data/third-eye-02_16_21.tsv")
file <- read_csv("data/bias_data/third-eye-08_31_21.tsv")
file
file <- read_csv("data/bias_data/third-eye-08_31_21.tsv",
skip = 1)
file
file <- read_csv("data/bias_data/third-eye-08_31_21.tsv")
file
file <- read_tsv("data/bias_data/third-eye-08_31_21.tsv")
file
file_1 <- read_tsv("data/bias_data/third-eye-08_31_21.tsv")
file_2 <- read_tsv("data/bias_data/third-eye-01_19_21.tsv")
file_3 <- read_tsv("data/bias_data/third-eye-09_28_21.tsv")
file_4 <- read_tsv("data/bias_data/third-eye-11_24_20.tsv")
file_5 <- read_tsv("data/bias_data/third-eye-12_22_20.tsv")
file_6 <- read_tsv("data/bias_data/third-eye-02_02_21.tsv")
file_7 <- read_tsv("data/bias_data/third-eye-12_29_20.tsv")
file_8 <- read_tsv("data/bias_data/third-eye-11_17_20.tsv")
file_9 <- read_tsv("data/bias_data/third-eye-10_12_21.tsv")
file_10 <- read_tsv("data/bias_data/third-eye-02_16_21.tsv")
knitr::opts_chunk$set(echo = TRUE)
library(gt)
library(quanteda)
library(broom)
library(skimr)
library(lubridate)
library(janitor)
library(dotwhisker)
library(tidytext)
library(haven)
library(ggthemes)
library(webshot)
library(stargazer)
library(tidyverse)
library(patchwork)
library(ggrepel)
library(ggpubr)
load("data/bias_data/bias_data_clean.RData")
text_corpus <- corpus(tidy_chyrons, text_field = "text")
text_corpus <- corpus(tidy_data, text_field = "text")
toks_2 <- tokens(text_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_remove(pattern = c("u201c", "u00b0", "u2014", "wopi", "avi", "ooo",
"000", "ito", "ynl", "f'avl", "foxnews.com",
"ufb02pi", "ufb021", "ufbo2l", "ufb02L", "rpm")) %>%
tokens_select(min_nchar = 3) %>%
tokens_ngrams(n = 2)
wordcloud_dfm_2 <- dfm(toks_2, groups = "channel")
textplot_wordcloud(wordcloud_dfm_2, comparison = T,
min_count = 200,
min_size = .5,
max_size = 3.7)
View(tidy_data)
textplot_wordcloud(wordcloud_dfm_2, comparison = T,
min_count = 1000,
min_size = .5,
max_size = 3.7)
textplot_wordcloud(wordcloud_dfm_2, comparison = T,
min_count = 200,
min_size = .5,
max_size = 3.7)
toks_2
wordcloud_dfm_2
text_corpus
toks_2 <- tokens(text_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_remove(pattern = c("u201c", "u00b0", "u2014", "wopi", "avi", "ooo",
"000", "ito", "ynl", "f'avl", "foxnews.com",
"ufb02pi", "ufb021", "ufbo2l", "ufb02L", "rpm")) %>%
tokens_select(min_nchar = 3) %>%
tokens_ngrams(n = 2)
wordcloud_dfm_2 <- dfm(toks_2, groups = "channel")
textplot_wordcloud(wordcloud_dfm_2, comparison = T,
min_count = 200,
min_size = .5,
max_size = 3.7)
afghanistan <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text))
View(afghanistan)
tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention) %>%
count(date, channel)
tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention) %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_segment() +
facet_wrap(~channel)
?geom_segment
tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention) %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_segment(exend = date, yend = 0) +
facet_wrap(~channel)
tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention) %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_segment(xend = date, yend = 0) +
facet_wrap(~channel)
tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention) %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_col() +
facet_wrap(~channel)
tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention) %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_col() +
facet_wrap(~channel) +
theme_clean()
tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention) %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_col() +
facet_wrap(~channel) +
theme_clean() +
labs(title = "Chyrons that mention Afghanistan",
x = "",
y = "# Chyrons")
afghanistan_df <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention)
afghanistan_chyron_counts <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention) %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_col() +
facet_wrap(~channel) +
theme_clean() +
labs(title = "Chyrons that mention Afghanistan",
x = "",
y = "# Chyrons")
?grepl
covid_df <- tidy_data %>%
mutate(text = tolower(text),
mention_covid = grepl("covid", text),
mention_corons = grepl("corona", text),
mention = if_else(mention_covid | mention_corons, TRUE, FALSE))
View(covid_df)
covid_df <- tidy_data %>%
mutate(text = tolower(text),
mention_covid = grepl("covid", text),
mention_corona = grepl("corona", text),
mention = if_else(mention_covid | mention_corona, TRUE, FALSE))
covid_df <- tidy_data %>%
mutate(text = tolower(text),
mention_covid = grepl("covid", text),
mention_corona = grepl("corona", text),
mention = if_else(mention_covid | mention_corona, TRUE, FALSE)) %>%
filter(mention)
covid_df
covid_df <- tidy_data %>%
mutate(text = tolower(text),
mention_covid = grepl("covid", text),
mention_corona = grepl("corona", text),
mention = if_else(mention_covid | mention_corona, TRUE, FALSE)) %>%
filter(mention)
covid_chyron_counts <- covid_df %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_col() +
facet_wrap(~channel) +
theme_clean() +
labs(title = "Chyrons that mention Covid",
x = "",
y = "# Chyrons")
covid_chyron_counts
impeach_df <- tidy_data %>%
mutate(text = tolower(text),
mention - grepl("impeach", text)) %>%
filter(mention)
impeach_df <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("impeach", text)) %>%
filter(mention)
impeach_df <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("impeach", text)) %>%
filter(mention)
impeach_chyron_counts <- impeach_df %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_col() +
facet_wrap(~channel) +
theme_clean() +
labs(title = "Chyrons that mention Impeachment",
x = "",
y = "# Chyrons")
impeach_chyron_counts
install.packages("tidytext")
library(tidytext)
?unnest_tokens
text_corpus <- corpus(tidy_chyrons, text_field = "text")
text_corpus <- corpus(tidy_data, text_field = "text")
afghanistan_df <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghan", text)) %>%
filter(mention)
afghanistan_chyron_counts <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghan", text)) %>%
filter(mention) %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_col() +
facet_wrap(~channel) +
theme_clean() +
labs(title = "Chyrons that mention Afghanistan",
x = "",
y = "# Chyrons")
afghanistan_chyron_counts
afghanistan_df <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention)
afghanistan_df <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention)
afghanistan_chyron_counts <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention) %>%
count(date, channel) %>%
ggplot(aes(x = date, y = n)) +
geom_col() +
facet_wrap(~channel) +
theme_clean() +
labs(title = "Chyrons that mention Afghanistan",
x = "",
y = "# Chyrons")
afghanistan_chyron_counts
afghanistan_corpus <- corpus(afghanistan_df, text_field = "text")
afghanistan_corpus
af_sentiment <- tokens(afghanistan_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_remove(pattern = c("u201c", "u00b0", "u2014", "wopi", "avi", "ooo",
"000", "ito", "ynl", "f'avl", "foxnews.com",
"ufb02pi", "ufb021", "ufbo2l", "ufb02L", "rpm")) %>%
tokens_select(min_nchar = 3)
af_sentiment <- tokens(afghanistan_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_remove(pattern = c("u201c", "u00b0", "u2014", "wopi", "avi", "ooo",
"000", "ito", "ynl", "f'avl", "foxnews.com",
"ufb02pi", "ufb021", "ufbo2l", "ufb02L", "rpm")) %>%
tokens_select(min_nchar = 3)  %>%
inner_join(get_sentiments("afinn"))
af_sentiment <- afghanistan_df %>%
unnest_tokens(word, text) %>%
inner_join(get_sentiments("afinn"))
install.packages("textdata")
library(textdata)
library(tidytext)
af_sentiment <- afghanistan_df %>%
unnest_tokens(word, text) %>%
inner_join(get_sentiments("afinn"))
af_sentiment
afghanistan_df <- tidy_data %>%
mutate(text = tolower(text),
chyron_id = 1:1544,
mention = grepl("afghanistan", text)) %>%
filter(mention)
afghanistan_df$chyron_id <- seq.int(nrow(afghanistan_df))
afghanistan_df
af_sentiment
afghanistan_df %>%
left_join(af_sentiment %>%
group_by(chyron_id) %>%
summarise(score = sum(value))) %>%
replace_na(list(score = 0))
afghanistan_df <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention)
afghanistan_df <- tidy_data %>%
mutate(text = tolower(text),
mention = grepl("afghanistan", text)) %>%
filter(mention)
afghanistan_df$chyron_id <- seq.int(nrow(afghanistan_df))
af_sentiment <- afghanistan_df %>%
unnest_tokens(word, text) %>%
inner_join(get_sentiments("afinn"))
af_sentiment
afghanistan_df %>%
left_join(af_sentiment %>%
group_by(chyron_id) %>%
summarise(score = sum(value))) %>%
replace_na(list(score = 0))
sentiment_scores %>%
ggplot(aes(x = date, y = score)) +
geom_point() +
facet_wrap(~channel) +
theme_clean()
sentiment_scores <- afghanistan_df %>%
left_join(af_sentiment %>%
group_by(chyron_id) %>%
summarise(score = sum(value))) %>%
replace_na(list(score = 0))
sentiment_scores %>%
ggplot(aes(x = date, y = score)) +
geom_point() +
facet_wrap(~channel) +
theme_clean()
sentiment_scores %>%
ggplot(aes(x = channel, y = score)) +
geom_boxplot() +
theme_clean()
